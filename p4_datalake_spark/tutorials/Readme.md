# Tutorials
## Purpose
- Store code & References used 
- For installation, tests, and starter

## Using Spark in local mode
### How to install Spark and Pyspark:
- [Install Spark and PySpark on MacOS](https://medium.com/swlh/pyspark-on-macos-installation-and-use-31f84ca61400)
- [Installing Java 11 ODK with Homebrew](https://medium.com/w-logs/installing-java-11-on-macos-with-homebrew-7f73c1e9fadf)
- [Launching Pyspark and Jupyter Notebook](https://www.sicara.ai/blog/2017-05-02-get-started-pyspark-jupyter-notebook-3-minutes)
- [Using Findspark](https://github.com/minrk/findspark)
- [Spark Session or Context](https://medium.com/@achilleus/spark-session-10d0d66d1d24#:~:text=Spark%20session%20is%20a%20unified,encapsulated%20in%20a%20Spark%20session.)

### localsparkcontext.py
- Assuming Spark and Pyspark are available locally
- Create a Spark Context
- Calculate Pi

### Read data from s3 with pandas
* connect to s3
* read csv or multiple files to Pandas

### Read data from s3 with pyspark
* create a spark cluster with AWS credentials
* read s3 bucket

## Ressources Used:
* [Amazon S3 tutorial](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-examples.html)
